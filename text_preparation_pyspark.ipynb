{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preparation Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "For this text preparation process we are going to use the **PySpark** library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col, rand, regexp_replace\n",
    "from sparknlp.annotator import Stemmer, LemmatizerModel\n",
    "from sparknlp.base import DocumentAssembler, Pipeline\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/09/14 20:17:09 WARN Utils: Your hostname, Cavelez resolves to a loopback address: 127.0.1.1; using 172.19.58.130 instead (on interface eth0)\n",
      "23/09/14 20:17:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/camilo/.local/share/virtualenvs/Trabajo2_almdatos-PXMnXu75/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/camilo/.ivy2/cache\n",
      "The jars for the packages stored in: /home/camilo/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-dadb7739-8301-45e2-8dd9-fcab3894b0dd;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.1.1 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.15.0 in central\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.12/5.1.1/spark-nlp_2.12-5.1.1.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp_2.12;5.1.1!spark-nlp_2.12.jar (17942ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.2/config-1.4.2.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.2!config.jar(bundle) (180ms)\n",
      "downloading https://repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar ...\n",
      "\t[SUCCESSFUL ] org.rocksdb#rocksdbjni;6.29.5!rocksdbjni.jar (3454ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.828/aws-java-sdk-bundle-1.11.828.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.828!aws-java-sdk-bundle.jar (11965ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/universal-automata/liblevenshtein/3.0.0/liblevenshtein-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.github.universal-automata#liblevenshtein;3.0.0!liblevenshtein.jar (121ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-storage/2.20.1/google-cloud-storage-2.20.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-storage;2.20.1!google-cloud-storage.jar (356ms)\n",
      "downloading https://repo1.maven.org/maven2/com/navigamez/greex/1.0/greex-1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.navigamez#greex;1.0!greex.jar (111ms)\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/tensorflow-cpu_2.12/0.4.4/tensorflow-cpu_2.12-0.4.4.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4!tensorflow-cpu_2.12.jar (13418ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/onnxruntime/onnxruntime/1.15.0/onnxruntime-1.15.0.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.onnxruntime#onnxruntime;1.15.0!onnxruntime.jar (4536ms)\n",
      "downloading https://repo1.maven.org/maven2/it/unimi/dsi/fastutil/7.0.12/fastutil-7.0.12.jar ...\n",
      "\t[SUCCESSFUL ] it.unimi.dsi#fastutil;7.0.12!fastutil.jar (977ms)\n",
      "downloading https://repo1.maven.org/maven2/org/projectlombok/lombok/1.16.8/lombok-1.16.8.jar ...\n",
      "\t[SUCCESSFUL ] org.projectlombok#lombok;1.16.8!lombok.jar (228ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#guava;31.1-jre!guava.jar(bundle) (264ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#failureaccess;1.0.1!failureaccess.jar(bundle) (112ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava!listenablefuture.jar (224ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/errorprone/error_prone_annotations/2.18.0/error_prone_annotations-2.18.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.errorprone#error_prone_annotations;2.18.0!error_prone_annotations.jar (105ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.j2objc#j2objc-annotations;1.3!j2objc-annotations.jar (124ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client/1.43.0/google-http-client-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client;1.43.0!google-http-client.jar (125ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-contrib-http-util/0.31.1/opencensus-contrib-http-util-0.31.1.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-contrib-http-util;0.31.1!opencensus-contrib-http-util.jar (121ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-jackson2/1.43.0/google-http-client-jackson2-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-jackson2;1.43.0!google-http-client-jackson2.jar (116ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-gson/1.43.0/google-http-client-gson-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-gson;1.43.0!google-http-client-gson.jar (161ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api-client/google-api-client/2.2.0/google-api-client-2.2.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api-client#google-api-client;2.2.0!google-api-client.jar (118ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.15/commons-codec-1.15.jar ...\n",
      "\t[SUCCESSFUL ] commons-codec#commons-codec;1.15!commons-codec.jar (161ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/oauth-client/google-oauth-client/1.34.1/google-oauth-client-1.34.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.oauth-client#google-oauth-client;1.34.1!google-oauth-client.jar (129ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-apache-v2/1.43.0/google-http-client-apache-v2-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-apache-v2;1.43.0!google-http-client-apache-v2.jar (118ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/apis/google-api-services-storage/v1-rev20220705-2.0.0/google-api-services-storage-v1-rev20220705-2.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0!google-api-services-storage.jar (114ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.gson#gson;2.10.1!gson.jar (121ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core/2.12.0/google-cloud-core-2.12.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core;2.12.0!google-cloud-core.jar (113ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-context/1.53.0/grpc-context-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-context;1.53.0!grpc-context.jar (130ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auto/value/auto-value-annotations/1.10.1/auto-value-annotations-1.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auto.value#auto-value-annotations;1.10.1!auto-value-annotations.jar (116ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auto/value/auto-value/1.10.1/auto-value-1.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auto.value#auto-value;1.10.1!auto-value.jar (356ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar ...\n",
      "\t[SUCCESSFUL ] javax.annotation#javax.annotation-api;1.3.2!javax.annotation-api.jar (103ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.2/commons-logging-1.2.jar ...\n",
      "\t[SUCCESSFUL ] commons-logging#commons-logging;1.2!commons-logging.jar (130ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core-http/2.12.0/google-cloud-core-http-2.12.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core-http;2.12.0!google-cloud-core-http.jar (114ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-appengine/1.43.0/google-http-client-appengine-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-appengine;1.43.0!google-http-client-appengine.jar (118ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/gax-httpjson/0.108.2/gax-httpjson-0.108.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax-httpjson;0.108.2!gax-httpjson.jar (144ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core-grpc/2.12.0/google-cloud-core-grpc-2.12.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core-grpc;2.12.0!google-cloud-core-grpc.jar (156ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-alts/1.53.0/grpc-alts-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-alts;1.53.0!grpc-alts.jar (339ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-grpclb/1.53.0/grpc-grpclb-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-grpclb;1.53.0!grpc-grpclb.jar (201ms)\n",
      "downloading https://repo1.maven.org/maven2/org/conscrypt/conscrypt-openjdk-uber/2.5.2/conscrypt-openjdk-uber-2.5.2.jar ...\n",
      "\t[SUCCESSFUL ] org.conscrypt#conscrypt-openjdk-uber;2.5.2!conscrypt-openjdk-uber.jar (767ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-auth/1.53.0/grpc-auth-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-auth;1.53.0!grpc-auth.jar (106ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-protobuf/1.53.0/grpc-protobuf-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-protobuf;1.53.0!grpc-protobuf.jar (117ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-protobuf-lite/1.53.0/grpc-protobuf-lite-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-protobuf-lite;1.53.0!grpc-protobuf-lite.jar (182ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-core/1.53.0/grpc-core-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-core;1.53.0!grpc-core.jar (634ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/gax/2.23.2/gax-2.23.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax;2.23.2!gax.jar (300ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/gax-grpc/2.23.2/gax-grpc-2.23.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax-grpc;2.23.2!gax-grpc.jar (163ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auth/google-auth-library-credentials/1.16.0/google-auth-library-credentials-1.16.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auth#google-auth-library-credentials;1.16.0!google-auth-library-credentials.jar (118ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auth/google-auth-library-oauth2-http/1.16.0/google-auth-library-oauth2-http-1.16.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auth#google-auth-library-oauth2-http;1.16.0!google-auth-library-oauth2-http.jar (121ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/api-common/2.6.2/api-common-2.6.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#api-common;2.6.2!api-common.jar (112ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-api/0.31.1/opencensus-api-0.31.1.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-api;0.31.1!opencensus-api.jar (145ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-iam-v1/1.9.2/proto-google-iam-v1-1.9.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-iam-v1;1.9.2!proto-google-iam-v1.jar (113ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.21.12/protobuf-java-3.21.12.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.21.12!protobuf-java.jar(bundle) (193ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java-util/3.21.12/protobuf-java-util-3.21.12.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java-util;3.21.12!protobuf-java-util.jar(bundle) (127ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-common-protos/2.14.2/proto-google-common-protos-2.14.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-common-protos;2.14.2!proto-google-common-protos.jar (209ms)\n",
      "downloading https://repo1.maven.org/maven2/org/threeten/threetenbp/1.6.5/threetenbp-1.6.5.jar ...\n",
      "\t[SUCCESSFUL ] org.threeten#threetenbp;1.6.5!threetenbp.jar (128ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-cloud-storage-v2/2.20.1-alpha/proto-google-cloud-storage-v2-2.20.1-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha!proto-google-cloud-storage-v2.jar (144ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/grpc-google-cloud-storage-v2/2.20.1-alpha/grpc-google-cloud-storage-v2-2.20.1-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha!grpc-google-cloud-storage-v2.jar (113ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/gapic-google-cloud-storage-v2/2.20.1-alpha/gapic-google-cloud-storage-v2-2.20.1-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha!gapic-google-cloud-storage-v2.jar (145ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.14.2/jackson-core-2.14.2.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-core;2.14.2!jackson-core.jar(bundle) (135ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (104ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-api/1.53.0/grpc-api-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-api;1.53.0!grpc-api.jar (125ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-stub/1.53.0/grpc-stub-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-stub;1.53.0!grpc-stub.jar (115ms)\n",
      "downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.31.0/checker-qual-3.31.0.jar ...\n",
      "\t[SUCCESSFUL ] org.checkerframework#checker-qual;3.31.0!checker-qual.jar (124ms)\n",
      "downloading https://repo1.maven.org/maven2/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar ...\n",
      "\t[SUCCESSFUL ] io.perfmark#perfmark-api;0.26.0!perfmark-api.jar (116ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar ...\n",
      "\t[SUCCESSFUL ] com.google.android#annotations;4.1.1.4!annotations.jar (101ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/mojo/animal-sniffer-annotations/1.22/animal-sniffer-annotations-1.22.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.mojo#animal-sniffer-annotations;1.22!animal-sniffer-annotations.jar (137ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-proto/0.2.0/opencensus-proto-0.2.0.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-proto;0.2.0!opencensus-proto.jar (157ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-services/1.53.0/grpc-services-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-services;1.53.0!grpc-services.jar (157ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/re2j/re2j/1.6/re2j-1.6.jar ...\n",
      "\t[SUCCESSFUL ] com.google.re2j#re2j;1.6!re2j.jar (124ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-netty-shaded/1.53.0/grpc-netty-shaded-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-netty-shaded;1.53.0!grpc-netty-shaded.jar (984ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-googleapis/1.53.0/grpc-googleapis-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-googleapis;1.53.0!grpc-googleapis.jar (127ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-xds/1.53.0/grpc-xds-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-xds;1.53.0!grpc-xds.jar (947ms)\n",
      "downloading https://repo1.maven.org/maven2/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar ...\n",
      "\t[SUCCESSFUL ] dk.brics.automaton#automaton;1.11-8!automaton.jar (115ms)\n",
      ":: resolution report :: resolve 40959ms :: artifacts dl 65066ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.2 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.1.1 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.15.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   75  |   75  |   75  |   3   ||   72  |   72  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-dadb7739-8301-45e2-8dd9-fcab3894b0dd\n",
      "\tconfs: [default]\n",
      "\t72 artifacts copied, 0 already retrieved (688146kB/57314ms)\n",
      "23/09/14 20:19:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/14 20:21:12 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/09/14 20:21:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/09/14 20:21:22 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/09/14 20:21:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/09/14 20:21:32 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/09/14 20:21:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/09/14 20:21:42 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/09/14 20:21:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/09/14 20:21:52 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/09/14 20:21:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/09/14 20:22:02 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/09/14 20:22:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/09/14 20:22:12 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/09/14 20:22:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n"
     ]
    }
   ],
   "source": [
    "#spark=SparkSession.builder.appName('nlp').getOrCreate()\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|            hashtags|\n",
      "+--------------------+--------------------+\n",
      "|2020 is the year ...|#votethemout #cli...|\n",
      "|Winter has not st...|#climatefriday #c...|\n",
      "|WEEK 55 of #Clima...|      #ClimateStrike|\n",
      "|A year of resista...|#greta #gretathun...|\n",
      "| HAPPY HOLIDAYS #...|#greta #gretathun...|\n",
      "|10 Questions to A...|#climatechange #n...|\n",
      "|#climatestrike #F...|#climatestrike #F...|\n",
      "|#ClimateChangeIsR...|#ClimateChangeIsR...|\n",
      "|My oldest daughte...|#climatestrike #l...|\n",
      "|Our toddler #POTU...|#POTUS #Time #Gre...|\n",
      "|\"\"\"The change is ...|#ClimateChange #c...|\n",
      "|Moments after #Im...|#ImpeachmentVote ...|\n",
      "|#climatestrike #C...|#climatestrike #C...|\n",
      "|Keep up the great...|#ClimateChangeIsR...|\n",
      "|Congratulations @...|#climatestrike #F...|\n",
      "|Even though I hop...|#HongKongProteste...|\n",
      "|*gretathunberg Is...|#PersonoftheYear ...|\n",
      "| Congratulations ...|#vegan #climatest...|\n",
      "|I get my energy a...|#ClimateStrike #F...|\n",
      "| THE CHAMBER OF C...|#greta #gretathun...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_in = \"twitterClimateData.csv\"\n",
    "df = spark.read.csv(path_in,inferSchema=True,header=True,sep=';')\n",
    "df = df.select([\"text\",\"hashtags\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- hashtags: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72405"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preparation process\n",
    "\n",
    "The goal of this process is to reduce the number of tokens but without eliminating the intepretability of the words, in order to create the best bag of words possible. We are going to split this process for each column of the DataFrame, first for `text` column and then for `hashtags` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preparation process for `Text` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization=Tokenizer(inputCol='text',outputCol='text_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens=tokenization.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|            hashtags|         text_tokens|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|2020 is the year ...|#votethemout #cli...|[2020, is, the, y...|\n",
      "|Winter has not st...|#climatefriday #c...|[winter, has, not...|\n",
      "|WEEK 55 of #Clima...|      #ClimateStrike|[week, 55, of, #c...|\n",
      "|A year of resista...|#greta #gretathun...|[a, year, of, res...|\n",
      "| HAPPY HOLIDAYS #...|#greta #gretathun...|[, happy, holiday...|\n",
      "|10 Questions to A...|#climatechange #n...|[10, questions, t...|\n",
      "|#climatestrike #F...|#climatestrike #F...|[#climatestrike, ...|\n",
      "|#ClimateChangeIsR...|#ClimateChangeIsR...|[#climatechangeis...|\n",
      "|My oldest daughte...|#climatestrike #l...|[my, oldest, daug...|\n",
      "|Our toddler #POTU...|#POTUS #Time #Gre...|[our, toddler, #p...|\n",
      "|\"\"\"The change is ...|#ClimateChange #c...|[\"\"\"the, change, ...|\n",
      "|Moments after #Im...|#ImpeachmentVote ...|[moments, after, ...|\n",
      "|#climatestrike #C...|#climatestrike #C...|[#climatestrike, ...|\n",
      "|Keep up the great...|#ClimateChangeIsR...|[keep, up, the, g...|\n",
      "|Congratulations @...|#climatestrike #F...|[congratulations,...|\n",
      "|Even though I hop...|#HongKongProteste...|[even, though, i,...|\n",
      "|*gretathunberg Is...|#PersonoftheYear ...|[*gretathunberg, ...|\n",
      "| Congratulations ...|#vegan #climatest...|[, congratulation...|\n",
      "|I get my energy a...|#ClimateStrike #F...|[i, get, my, ener...|\n",
      "| THE CHAMBER OF C...|#greta #gretathun...|[, the, chamber, ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tokens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_removal=StopWordsRemover(inputCol='text_tokens',outputCol='refined_text_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            hashtags|         text_tokens| refined_text_tokens|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|2020 is the year ...|#votethemout #cli...|[2020, is, the, y...|[2020, year, #vot...|\n",
      "|Winter has not st...|#climatefriday #c...|[winter, has, not...|[winter, stopped,...|\n",
      "|WEEK 55 of #Clima...|      #ClimateStrike|[week, 55, of, #c...|[week, 55, #clima...|\n",
      "|A year of resista...|#greta #gretathun...|[a, year, of, res...|[year, resistance...|\n",
      "| HAPPY HOLIDAYS #...|#greta #gretathun...|[, happy, holiday...|[, happy, holiday...|\n",
      "|10 Questions to A...|#climatechange #n...|[10, questions, t...|[10, questions, a...|\n",
      "|#climatestrike #F...|#climatestrike #F...|[#climatestrike, ...|[#climatestrike, ...|\n",
      "|#ClimateChangeIsR...|#ClimateChangeIsR...|[#climatechangeis...|[#climatechangeis...|\n",
      "|My oldest daughte...|#climatestrike #l...|[my, oldest, daug...|[oldest, daughter...|\n",
      "|Our toddler #POTU...|#POTUS #Time #Gre...|[our, toddler, #p...|[toddler, #potus,...|\n",
      "|\"\"\"The change is ...|#ClimateChange #c...|[\"\"\"the, change, ...|[\"\"\"the, change, ...|\n",
      "|Moments after #Im...|#ImpeachmentVote ...|[moments, after, ...|[moments, #impeac...|\n",
      "|#climatestrike #C...|#climatestrike #C...|[#climatestrike, ...|[#climatestrike, ...|\n",
      "|Keep up the great...|#ClimateChangeIsR...|[keep, up, the, g...|[keep, great, wor...|\n",
      "|Congratulations @...|#climatestrike #F...|[congratulations,...|[congratulations,...|\n",
      "|Even though I hop...|#HongKongProteste...|[even, though, i,...|[even, though, ho...|\n",
      "|*gretathunberg Is...|#PersonoftheYear ...|[*gretathunberg, ...|[*gretathunberg, ...|\n",
      "| Congratulations ...|#vegan #climatest...|[, congratulation...|[, congratulation...|\n",
      "|I get my energy a...|#ClimateStrike #F...|[i, get, my, ener...|[get, energy, hop...|\n",
      "| THE CHAMBER OF C...|#greta #gretathun...|[, the, chamber, ...|[, chamber, comme...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refined_text_df=stopword_removal.transform(df_tokens)\n",
    "refined_text_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+----------------+\n",
      "|                text|            hashtags|         text_tokens| refined_text_tokens|token_text_count|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------------+\n",
      "|2020 is the year ...|#votethemout #cli...|[2020, is, the, y...|[2020, year, #vot...|              21|\n",
      "|Winter has not st...|#climatefriday #c...|[winter, has, not...|[winter, stopped,...|              11|\n",
      "|WEEK 55 of #Clima...|      #ClimateStrike|[week, 55, of, #c...|[week, 55, #clima...|              32|\n",
      "|A year of resista...|#greta #gretathun...|[a, year, of, res...|[year, resistance...|              25|\n",
      "| HAPPY HOLIDAYS #...|#greta #gretathun...|[, happy, holiday...|[, happy, holiday...|              23|\n",
      "|10 Questions to A...|#climatechange #n...|[10, questions, t...|[10, questions, a...|              21|\n",
      "|#climatestrike #F...|#climatestrike #F...|[#climatestrike, ...|[#climatestrike, ...|              15|\n",
      "|#ClimateChangeIsR...|#ClimateChangeIsR...|[#climatechangeis...|[#climatechangeis...|               3|\n",
      "|My oldest daughte...|#climatestrike #l...|[my, oldest, daug...|[oldest, daughter...|              15|\n",
      "|Our toddler #POTU...|#POTUS #Time #Gre...|[our, toddler, #p...|[toddler, #potus,...|              19|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "len_udf = udf(lambda s: len(s), IntegerType()) \n",
    "\n",
    "refined_text_df = refined_text_df.withColumn(\"token_text_count\", len_udf(col('refined_text_tokens')))\n",
    "\n",
    "refined_text_df.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Spark NLP Stemming and Lemmatizing - Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "\n",
    "stemmer = Stemmer().setInputCols([\"refined_text_tokens\"]).setOutputCol(\"stemming_text_tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ / ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[  ]Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \\ ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['refined_text_tokens']) \\\n",
    "     .setOutputCol('lemmatize_text_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documentAssembler = DocumentAssembler().setInputCol(text_col).setOutputCol('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Wrong or missing inputCols annotators in Stemmer_2ef55dc5f5bd.\n\nCurrent inputCols: refined_text_tokens. Dataset's columns:\n(column_name=text,is_nlp_annotator=false)\n(column_name=hashtags,is_nlp_annotator=false)\n(column_name=text_tokens,is_nlp_annotator=false)\n(column_name=refined_text_tokens,is_nlp_annotator=false)\n(column_name=token_text_count,is_nlp_annotator=false).\nMake sure such annotators exist in your pipeline, with the right output names and that they have following annotator types: token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m/home/camilo/Trabajo2_almdatos/text_preparation_pyspark.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/camilo/Trabajo2_almdatos/text_preparation_pyspark.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m refined_text_df \u001b[39m=\u001b[39m stemmer\u001b[39m.\u001b[39;49mtransform(refined_text_df)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Trabajo2_almdatos-PXMnXu75/lib/python3.11/site-packages/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(dataset)\n\u001b[1;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParams must be a param map but got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Trabajo2_almdatos-PXMnXu75/lib/python3.11/site-packages/pyspark/ml/wrapper.py:398\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 398\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mtransform(dataset\u001b[39m.\u001b[39;49m_jdf), dataset\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Trabajo2_almdatos-PXMnXu75/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Trabajo2_almdatos-PXMnXu75/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Wrong or missing inputCols annotators in Stemmer_2ef55dc5f5bd.\n\nCurrent inputCols: refined_text_tokens. Dataset's columns:\n(column_name=text,is_nlp_annotator=false)\n(column_name=hashtags,is_nlp_annotator=false)\n(column_name=text_tokens,is_nlp_annotator=false)\n(column_name=refined_text_tokens,is_nlp_annotator=false)\n(column_name=token_text_count,is_nlp_annotator=false).\nMake sure such annotators exist in your pipeline, with the right output names and that they have following annotator types: token"
     ]
    }
   ],
   "source": [
    "refined_text_df = stemmer.transform(refined_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_text_df = lemmatizer.transform(refined_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_text_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Text preparation process for `Hashtags` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|            hashtags|   hashtags_without#|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|2020 is the year ...|#votethemout #cli...|votethemout clima...|\n",
      "|Winter has not st...|#climatefriday #c...|climatefriday cli...|\n",
      "|WEEK 55 of #Clima...|      #ClimateStrike|       ClimateStrike|\n",
      "|A year of resista...|#greta #gretathun...|greta gretathunbe...|\n",
      "| HAPPY HOLIDAYS #...|#greta #gretathun...|greta gretathunbe...|\n",
      "|10 Questions to A...|#climatechange #n...|climatechange nat...|\n",
      "|#climatestrike #F...|#climatestrike #F...|climatestrike Fri...|\n",
      "|#ClimateChangeIsR...|#ClimateChangeIsR...|ClimateChangeIsRe...|\n",
      "|My oldest daughte...|#climatestrike #l...|climatestrike let...|\n",
      "|Our toddler #POTU...|#POTUS #Time #Gre...|POTUS Time GretaT...|\n",
      "|\"\"\"The change is ...|#ClimateChange #c...|ClimateChange cli...|\n",
      "|Moments after #Im...|#ImpeachmentVote ...|ImpeachmentVote C...|\n",
      "|#climatestrike #C...|#climatestrike #C...|climatestrike Cli...|\n",
      "|Keep up the great...|#ClimateChangeIsR...|ClimateChangeIsRe...|\n",
      "|Congratulations @...|#climatestrike #F...|climatestrike Fri...|\n",
      "|Even though I hop...|#HongKongProteste...|HongKongProtester...|\n",
      "|*gretathunberg Is...|#PersonoftheYear ...|PersonoftheYear H...|\n",
      "| Congratulations ...|#vegan #climatest...| vegan climatestrike|\n",
      "|I get my energy a...|#ClimateStrike #F...|ClimateStrike Fir...|\n",
      "| THE CHAMBER OF C...|#greta #gretathun...|greta gretathunbe...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"hashtags_without#\",regexp_replace(\"hashtags\",\"#\",\"\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization=Tokenizer(inputCol='hashtags_without#',outputCol='hashtags_tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hashtags=tokenization.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            hashtags|   hashtags_without#|     hashtags_tokens|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|2020 is the year ...|#votethemout #cli...|votethemout clima...|[votethemout, cli...|\n",
      "|Winter has not st...|#climatefriday #c...|climatefriday cli...|[climatefriday, c...|\n",
      "|WEEK 55 of #Clima...|      #ClimateStrike|       ClimateStrike|     [climatestrike]|\n",
      "|A year of resista...|#greta #gretathun...|greta gretathunbe...|[greta, gretathun...|\n",
      "| HAPPY HOLIDAYS #...|#greta #gretathun...|greta gretathunbe...|[greta, gretathun...|\n",
      "|10 Questions to A...|#climatechange #n...|climatechange nat...|[climatechange, n...|\n",
      "|#climatestrike #F...|#climatestrike #F...|climatestrike Fri...|[climatestrike, f...|\n",
      "|#ClimateChangeIsR...|#ClimateChangeIsR...|ClimateChangeIsRe...|[climatechangeisr...|\n",
      "|My oldest daughte...|#climatestrike #l...|climatestrike let...|[climatestrike, l...|\n",
      "|Our toddler #POTU...|#POTUS #Time #Gre...|POTUS Time GretaT...|[potus, time, gre...|\n",
      "|\"\"\"The change is ...|#ClimateChange #c...|ClimateChange cli...|[climatechange, c...|\n",
      "|Moments after #Im...|#ImpeachmentVote ...|ImpeachmentVote C...|[impeachmentvote,...|\n",
      "|#climatestrike #C...|#climatestrike #C...|climatestrike Cli...|[climatestrike, c...|\n",
      "|Keep up the great...|#ClimateChangeIsR...|ClimateChangeIsRe...|[climatechangeisr...|\n",
      "|Congratulations @...|#climatestrike #F...|climatestrike Fri...|[climatestrike, f...|\n",
      "|Even though I hop...|#HongKongProteste...|HongKongProtester...|[hongkongproteste...|\n",
      "|*gretathunberg Is...|#PersonoftheYear ...|PersonoftheYear H...|[personoftheyear,...|\n",
      "| Congratulations ...|#vegan #climatest...| vegan climatestrike|[vegan, climatest...|\n",
      "|I get my energy a...|#ClimateStrike #F...|ClimateStrike Fir...|[climatestrike, f...|\n",
      "| THE CHAMBER OF C...|#greta #gretathun...|greta gretathunbe...|[greta, gretathun...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hashtags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_removal=StopWordsRemover(inputCol='hashtags_tokens',outputCol='refined_hashtags_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-----------------------+\n",
      "|                text|            hashtags|   hashtags_without#|     hashtags_tokens|refined_hashtags_tokens|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------------------+\n",
      "|2020 is the year ...|#votethemout #cli...|votethemout clima...|[votethemout, cli...|   [votethemout, cli...|\n",
      "|Winter has not st...|#climatefriday #c...|climatefriday cli...|[climatefriday, c...|   [climatefriday, c...|\n",
      "|WEEK 55 of #Clima...|      #ClimateStrike|       ClimateStrike|     [climatestrike]|        [climatestrike]|\n",
      "|A year of resista...|#greta #gretathun...|greta gretathunbe...|[greta, gretathun...|   [greta, gretathun...|\n",
      "| HAPPY HOLIDAYS #...|#greta #gretathun...|greta gretathunbe...|[greta, gretathun...|   [greta, gretathun...|\n",
      "|10 Questions to A...|#climatechange #n...|climatechange nat...|[climatechange, n...|   [climatechange, n...|\n",
      "|#climatestrike #F...|#climatestrike #F...|climatestrike Fri...|[climatestrike, f...|   [climatestrike, f...|\n",
      "|#ClimateChangeIsR...|#ClimateChangeIsR...|ClimateChangeIsRe...|[climatechangeisr...|   [climatechangeisr...|\n",
      "|My oldest daughte...|#climatestrike #l...|climatestrike let...|[climatestrike, l...|   [climatestrike, l...|\n",
      "|Our toddler #POTU...|#POTUS #Time #Gre...|POTUS Time GretaT...|[potus, time, gre...|   [potus, time, gre...|\n",
      "|\"\"\"The change is ...|#ClimateChange #c...|ClimateChange cli...|[climatechange, c...|   [climatechange, c...|\n",
      "|Moments after #Im...|#ImpeachmentVote ...|ImpeachmentVote C...|[impeachmentvote,...|   [impeachmentvote,...|\n",
      "|#climatestrike #C...|#climatestrike #C...|climatestrike Cli...|[climatestrike, c...|   [climatestrike, c...|\n",
      "|Keep up the great...|#ClimateChangeIsR...|ClimateChangeIsRe...|[climatechangeisr...|   [climatechangeisr...|\n",
      "|Congratulations @...|#climatestrike #F...|climatestrike Fri...|[climatestrike, f...|   [climatestrike, f...|\n",
      "|Even though I hop...|#HongKongProteste...|HongKongProtester...|[hongkongproteste...|   [hongkongproteste...|\n",
      "|*gretathunberg Is...|#PersonoftheYear ...|PersonoftheYear H...|[personoftheyear,...|   [personoftheyear,...|\n",
      "| Congratulations ...|#vegan #climatest...| vegan climatestrike|[vegan, climatest...|   [vegan, climatest...|\n",
      "|I get my energy a...|#ClimateStrike #F...|ClimateStrike Fir...|[climatestrike, f...|   [climatestrike, f...|\n",
      "| THE CHAMBER OF C...|#greta #gretathun...|greta gretathunbe...|[greta, gretathun...|   [greta, gretathun...|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refined_hashtags_df=stopword_removal.transform(df_hashtags)\n",
    "refined_hashtags_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+\n",
      "|                text|            hashtags|   hashtags_without#|     hashtags_tokens|refined_hashtags_tokens|token_hashtags_count|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+\n",
      "|2020 is the year ...|#votethemout #cli...|votethemout clima...|[votethemout, cli...|   [votethemout, cli...|                   3|\n",
      "|Winter has not st...|#climatefriday #c...|climatefriday cli...|[climatefriday, c...|   [climatefriday, c...|                   3|\n",
      "|WEEK 55 of #Clima...|      #ClimateStrike|       ClimateStrike|     [climatestrike]|        [climatestrike]|                   1|\n",
      "|A year of resista...|#greta #gretathun...|greta gretathunbe...|[greta, gretathun...|   [greta, gretathun...|                  11|\n",
      "| HAPPY HOLIDAYS #...|#greta #gretathun...|greta gretathunbe...|[greta, gretathun...|   [greta, gretathun...|                  15|\n",
      "|10 Questions to A...|#climatechange #n...|climatechange nat...|[climatechange, n...|   [climatechange, n...|                  14|\n",
      "|#climatestrike #F...|#climatestrike #F...|climatestrike Fri...|[climatestrike, f...|   [climatestrike, f...|                  13|\n",
      "|#ClimateChangeIsR...|#ClimateChangeIsR...|ClimateChangeIsRe...|[climatechangeisr...|   [climatechangeisr...|                   3|\n",
      "|My oldest daughte...|#climatestrike #l...|climatestrike let...|[climatestrike, l...|   [climatestrike, l...|                   3|\n",
      "|Our toddler #POTU...|#POTUS #Time #Gre...|POTUS Time GretaT...|[potus, time, gre...|   [potus, time, gre...|                  11|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len_udf = udf(lambda s: len(s), IntegerType()) \n",
    "\n",
    "refined_hashtags_df = refined_hashtags_df.withColumn(\"token_hashtags_count\", len_udf(col('refined_hashtags_tokens')))\n",
    "\n",
    "refined_hashtags_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Spark NLP Stemming and Lemmatizing - Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "\n",
    "stemmer = Stemmer().setInputCols([\"refined_text_tokens\"]).setOutputCol(\"stemming_text_tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import LemmatizerModel\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['refined_text_tokens']) \\\n",
    "     .setOutputCol('lemmatize_text_tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1) for stemming and lemmatizing \n",
    "* https://www.johnsnowlabs.com/boost-your-nlp-results-with-spark-nlp-stemming-and-lemmatizing-techniques/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trabajo2_almdatos-PXMnXu75",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
